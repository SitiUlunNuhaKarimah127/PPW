{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1QzBNhFN0y5WPlIGveFchwF1CenfK7CC6","authorship_tag":"ABX9TyOa3sw7v0iS1ic9oCV7oef2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Scraping Berita CNN Indonesia"],"metadata":{"id":"Cod-DnsCecf9"}},{"cell_type":"markdown","source":["## Import library yang diperlukan\n"],"metadata":{"id":"GETIABP3PWgQ"}},{"cell_type":"markdown","source":["Code di bawah adalah kode Python yang mengimport tiga library yaitu BeautifulSoup, requests, dan pandas. Library BeautifulSoup digunakan untuk melakukan web scraping atau mengambil data dari halaman web. Library requests digunakan untuk mengambil elemen HTML dari sebuah alamat website yang diberikan, dan ini akan menjadi input bagi Beautiful Soup untuk melakukan parsing halaman. Sedangkan library pandas digunakan untuk memanipulasi data yang telah diambil dari halaman web.\n","\n","Berikut adalah penjelasan singkat mengenai tiga library tersebut:\n","- **BeautifulSoup**: digunakan untuk melakukan web scraping atau mengambil data dari halaman web. Library ini dapat membaca file HTML dan XML, dan mengubahnya menjadi struktur data yang mudah dibaca dan dimanipulasi.\n","- **requests**: digunakan untuk mengambil elemen HTML dari sebuah alamat website yang diberikan. Library ini memungkinkan kita untuk mengirimkan HTTP/1.1 requests dengan mudah.\n","- **pandas**: digunakan untuk memanipulasi data yang telah diambil dari halaman web. Library ini menyediakan struktur data yang fleksibel dan efisien untuk melakukan analisis data.\n","\n","Kode tersebut mengimport library BeautifulSoup dengan nama alias `BeautifulSoup`, library requests tanpa alias, dan library pandas dengan nama alias `pd`. Setelah library-library tersebut diimport, kita dapat menggunakan fungsi-fungsi yang disediakan oleh masing-masing library untuk melakukan web scraping dan memanipulasi data yang telah diambil.\n","\n"],"metadata":{"id":"UlnaA7m5f15T"}},{"cell_type":"code","execution_count":10,"metadata":{"id":"2QAF04QYvw8U","executionInfo":{"status":"ok","timestamp":1699616828323,"user_tz":-420,"elapsed":367,"user":{"displayName":"Siti Ulun Nuha Karimah","userId":"02748323530668587194"}}},"outputs":[],"source":["from bs4 import BeautifulSoup\n","import requests\n","import pandas as pd"]},{"cell_type":"markdown","source":["## Fungsi yang digunakan untuk mengambil link navbar menggunakan function get_nav_link()"],"metadata":{"id":"iCpZ-h2mIqR4"}},{"cell_type":"markdown","source":["Code di bawah adalah sebuah fungsi Python yang bernama `get_nav_link()`. Fungsi ini digunakan untuk mengambil link dari menu navigasi pada halaman web CNN Indonesia.\n","\n","Berikut adalah penjelasan singkat mengenai cara kerja fungsi tersebut:\n","- Pertama-tama, fungsi ini akan melakukan request ke halaman web CNN Indonesia menggunakan library requests.\n","- Setelah itu, fungsi akan memeriksa apakah respon yang diterima memiliki status code 200 atau tidak. Jika status code-nya adalah 200, maka fungsi akan melanjutkan eksekusinya. Jika tidak, maka fungsi akan mencetak pesan error.\n","- Selanjutnya, fungsi akan mencari elemen HTML yang memiliki tag `a` dan class `navbar__item` menggunakan library BeautifulSoup. Elemen-elemen tersebut merepresentasikan menu navigasi pada halaman web CNN Indonesia.\n","- Fungsi akan menyimpan link dari masing-masing menu navigasi ke dalam sebuah dictionary dengan format `{nama_menu: link_menu}`. Namun, menu dengan nama \"Home\" akan diabaikan.\n","- Setelah itu, fungsi akan melakukan update pada link dari masing-masing menu navigasi. Fungsi akan melakukan request ke halaman web yang terkait dengan link menu navigasi tersebut, dan mencari elemen HTML yang memiliki tag `a` dan atribut `dtr-act` dengan nilai \"button indeks berita\". Fungsi akan mengambil nilai dari atribut `href` dari elemen tersebut, dan menggunakannya sebagai link baru untuk menu navigasi tersebut.\n","- Setelah semua link menu navigasi telah diperbarui, fungsi akan mengembalikan dictionary yang berisi nama dan link dari masing-masing menu navigasi.\n","\n","\n"],"metadata":{"id":"WbHI_JqfhIRc"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"zy75V93gtMfB","executionInfo":{"status":"ok","timestamp":1699616828787,"user_tz":-420,"elapsed":16,"user":{"displayName":"Siti Ulun Nuha Karimah","userId":"02748323530668587194"}}},"outputs":[],"source":["def get_nav_link():\n","  response = requests.get('https://www.cnnindonesia.com')\n","\n","  # Untuk mengecek respon url dan mencari menu sidebar\n","  if response.status_code == 200:\n","    # Get Nav\n","    html = response.content\n","    nav = BeautifulSoup(html, 'html.parser').find_all('a', class_='navbar__item')\n","    nav_link = {i.text.strip() : i.get('href') for i in nav if i.text.strip() not in ['Home']}\n","\n","    # Update Nav Link\n","    for category, link in nav_link.items():\n","      nav_content = requests.get(link).content\n","      new_link = BeautifulSoup(nav_content, 'html.parser').find('a', {'dtr-act' : 'button indeks berita'}).get('href')\n","      nav_link[category] = new_link\n","\n","    return nav_link\n","\n","  else:\n","    print(f'Response https://www.cnnindonesia.com : {response.status_code}')"]},{"cell_type":"markdown","source":["## Fungsi yang digunakan untuk mengambil data menggunakan function get_data()"],"metadata":{"id":"YjhnX7mHPDBX"}},{"cell_type":"markdown","source":["Code di bawah adalah sebuah fungsi Python yang bernama `get_data(url)`. Fungsi ini digunakan untuk mengambil data dari halaman web yang diberikan melalui parameter `url`.\n","\n","Berikut adalah penjelasan singkat mengenai cara kerja fungsi tersebut:\n","- Pertama-tama, fungsi ini akan mencetak URL yang diberikan sebagai parameter.\n","- Selanjutnya, fungsi akan melakukan request ke halaman web yang diberikan menggunakan library requests.\n","- Fungsi akan memeriksa apakah respon yang diterima memiliki status code 200 atau tidak. Jika status code-nya adalah 200, maka fungsi akan melanjutkan eksekusinya. Jika tidak, maka fungsi akan mengembalikan nilai `None`.\n","- Fungsi akan mencari elemen HTML yang memiliki tag `h1` dan class `mb-2 text-[28px] leading-9 text-cnn_black` menggunakan library BeautifulSoup. Elemen tersebut merepresentasikan judul artikel pada halaman web yang diberikan.\n","- Fungsi juga akan mencari elemen HTML yang memiliki tag `div` dan class `text-cnn_grey text-sm mb-4` menggunakan library BeautifulSoup. Elemen tersebut merepresentasikan tanggal publikasi artikel pada halaman web yang diberikan.\n","- Selanjutnya, fungsi akan mencari elemen HTML yang memiliki tag `a` dan atribut `dtr-evt` dengan nilai \"breadcrumb\" menggunakan library BeautifulSoup. Elemen tersebut merepresentasikan kategori artikel pada halaman web yang diberikan.\n","- Fungsi akan mencari elemen HTML yang memiliki tag `div` dan class `detail-text text-cnn_black text-sm grow min-w-0` menggunakan library BeautifulSoup. Elemen tersebut merepresentasikan isi artikel pada halaman web yang diberikan.\n","- Fungsi akan mengambil teks dari masing-masing elemen `p` pada elemen HTML tersebut, dan menyimpannya ke dalam sebuah string. Namun, fungsi akan mengabaikan teks yang memiliki nilai \"SCROLL TO RESUME CONTENT\" atau \"ADVERTISEMENT\".\n","- Setelah itu, fungsi akan menyimpan semua data yang telah diambil ke dalam sebuah list dengan format `[url, judul, tanggal, isi, kategori]`, dan mengembalikan list tersebut.\n","\n"],"metadata":{"id":"OAj4ECeRi_Yp"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"d7jEkpmyvziQ","executionInfo":{"status":"ok","timestamp":1699616828788,"user_tz":-420,"elapsed":16,"user":{"displayName":"Siti Ulun Nuha Karimah","userId":"02748323530668587194"}}},"outputs":[],"source":["def get_data(url):\n","  response = requests.get(url)\n","  if response.status_code == 200:\n","    data = []\n","    html = response.content\n","    content = BeautifulSoup(html, 'html.parser')\n","    judul = content.find('h1', class_='mb-2 text-[28px] leading-9 text-cnn_black').text.strip()\n","    date = content.find('div', class_='text-cnn_grey text-sm mb-4').text.strip()\n","    category = content.find_all('a', {'dtr-evt' : 'breadcrumb'})[1].text.strip()\n","    article = content.find('div', class_='detail-text text-cnn_black text-sm grow min-w-0').find_all('p')\n","    text = ''\n","    for i in article:\n","      if i.text.strip() not in ['SCROLL TO RESUME CONTENT', 'ADVERTISEMENT']:\n","        text += i.text.strip() + ' '\n","    data.append(url)\n","    data.append(judul)\n","    data.append(date)\n","    data.append(text.replace('\\xa0', ''))\n","    data.append(category.strip())\n","    return data"]},{"cell_type":"markdown","source":["## Fungsi yang digunakan untuk mengambil content menggunakan function get_content()"],"metadata":{"id":"8_QlL6zOO9YA"}},{"cell_type":"markdown","source":["Code di atas adalah sebuah fungsi Python yang bernama `get_content(url, len_data, target)`. Fungsi ini digunakan untuk mengambil dan mengurai konten berita dari halaman web dengan URL yang diberikan. Fungsi ini akan mengambil data dari halaman web yang diberikan melalui parameter `url`, dan akan terus mengambil data dari halaman web selanjutnya hingga jumlah data yang telah diambil mencapai nilai `target`. Fungsi ini akan mengembalikan semua data yang telah diambil dalam bentuk list.\n","\n","Berikut adalah penjelasan singkat mengenai cara kerja fungsi tersebut:\n","- Pertama-tama, fungsi ini akan membuat sebuah list kosong yang akan digunakan untuk menyimpan data yang telah diambil.\n","- Selanjutnya, fungsi akan melakukan request ke halaman web yang diberikan menggunakan library requests.\n","- Fungsi akan memeriksa apakah respon yang diterima memiliki status code 200 atau tidak. Jika status code-nya adalah 200, maka fungsi akan melanjutkan eksekusinya. Jika tidak, maka fungsi akan mencetak pesan error.\n","- Fungsi akan mencari elemen HTML yang memiliki tag `div` dan class `flex flex-col gap-5` menggunakan library BeautifulSoup. Elemen tersebut merepresentasikan container yang berisi artikel-artikel pada halaman web yang diberikan.\n","- Fungsi akan mencari semua elemen HTML yang memiliki tag `article` dan class `flex-grow` pada container tersebut. Elemen-elemen tersebut merepresentasikan artikel-artikel pada halaman web yang diberikan.\n","- Fungsi akan mencari elemen HTML yang memiliki tag `a` dan atribut `dtr-act` dengan nilai \"halaman selanjutnya\" menggunakan library BeautifulSoup. Elemen tersebut merepresentasikan link menuju halaman web selanjutnya.\n","- Fungsi akan melakukan iterasi pada setiap artikel pada halaman web tersebut. Fungsi akan memeriksa apakah artikel tersebut memiliki subjudul atau tidak. Jika artikel tersebut tidak memiliki subjudul dan judulnya tidak mengandung karakter \":\", maka fungsi akan mengambil link dari artikel tersebut dan memanggil fungsi `get_data()` untuk mengambil data dari halaman web tersebut. Data yang telah diambil akan disimpan ke dalam list yang telah dibuat sebelumnya.\n","- Fungsi akan terus melakukan iterasi pada artikel-artikel pada halaman web tersebut hingga jumlah data yang telah diambil mencapai nilai `target`. Jika jumlah data yang telah diambil sudah mencapai nilai `target`, maka fungsi akan mengembalikan semua data yang telah diambil beserta link menuju halaman web selanjutnya. Jika belum, maka fungsi akan melakukan request ke halaman web selanjutnya dan mengulangi proses yang sama.\n","\n"],"metadata":{"id":"7pi6xgd5j2p5"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"iGzhueIhv1ur","executionInfo":{"status":"ok","timestamp":1699616828789,"user_tz":-420,"elapsed":15,"user":{"displayName":"Siti Ulun Nuha Karimah","userId":"02748323530668587194"}}},"outputs":[],"source":["def get_content(url, len_data, target):\n","  data = []\n","  response = requests.get(url)\n","  if response.status_code == 200:\n","    html = response.content\n","    container = BeautifulSoup(html, 'html.parser')\n","    list_content = container.find('div', class_='flex flex-col gap-5').find_all('article', class_='flex-grow')\n","    next_button = container.find('a', {'dtr-act' : 'halaman selanjutnya'}).get('href')\n","    idx = 0\n","\n","    while idx != len(list_content):\n","      subjudul = list_content[idx].find('span', class_='text-cnn_red block subjudul mb-1')\n","      if len(list_content[idx].find('h2').text.strip().split(':')) < 2 and subjudul == None:\n","        if len_data != target:\n","          link_content = list_content[idx].find('a').get('href')\n","          data_berita = get_data(link_content)\n","          data.append(data_berita)\n","          len_data += 1\n","          print(data_berita)\n","        else:\n","          break\n","          return (data, next_button)\n","\n","      idx += 1\n","\n","  else:\n","    print(f'Response {url} : {response.status_code}')\n","  return (data, next_button)\n"]},{"cell_type":"markdown","source":["## Function scraping_cnn()"],"metadata":{"id":"z9CvUeP5O1qJ"}},{"cell_type":"markdown","source":["Fungsi `scraping_cnn(category=['Nasional'], num_data=2)` adalah sebuah fungsi Python yang digunakan untuk melakukan web scraping pada halaman web CNN Indonesia. Fungsi ini akan mengambil data dari beberapa kategori berita pada halaman web CNN Indonesia dan menyimpannya ke dalam sebuah file CSV.\n","\n","Berikut adalah penjelasan singkat mengenai cara kerja fungsi tersebut:\n","- Pertama-tama, fungsi ini akan memanggil fungsi `get_nav_link()` untuk mengambil link dari menu navigasi pada halaman web CNN Indonesia.\n","- Selanjutnya, fungsi akan melakukan iterasi pada setiap kategori berita yang diberikan melalui parameter `category`. Untuk setiap kategori, fungsi akan terus mengambil data dari halaman web tersebut hingga jumlah data yang telah diambil mencapai nilai `num_data`.\n","- Fungsi akan memanggil fungsi `get_content()` untuk mengambil data dari halaman web yang terkait dengan kategori tersebut. Fungsi `get_content()` akan terus melakukan pengambilan data hingga jumlah data yang telah diambil mencapai nilai `num_data`.\n","- Setelah semua data telah diambil, fungsi akan menyimpan data tersebut ke dalam sebuah file CSV dengan nama \"Data Berita CNN.csv\".\n"],"metadata":{"id":"hMXHQj5fmvma"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"y1cON4ThwZNA","executionInfo":{"status":"ok","timestamp":1699616828790,"user_tz":-420,"elapsed":14,"user":{"displayName":"Siti Ulun Nuha Karimah","userId":"02748323530668587194"}}},"outputs":[],"source":["def scraping_cnn(category=['Nasional'], num_data=2):\n","  category_link = get_nav_link()\n","  data = []\n","\n","  for i in category:\n","    len_data_category = 0\n","    while len_data_category != num_data:\n","      new_data, next_button = get_content(category_link[i], len_data_category, num_data)\n","      data += new_data\n","      len_data_category += len(new_data)\n","      category_link[i] = next_button\n","\n","  print(f'Berhasil Mengambil data sebanyak {len(data)} berita dengan {len(category)} Category')\n","\n","  df = pd.DataFrame(data, columns=['Url', 'Judul', 'Tanggal', 'Artikel', 'Category'])\n","  df.to_csv('Data Berita CNN.csv', index=False)"]},{"cell_type":"markdown","source":["## Pemanggilan Fungsi scraping_cnn()"],"metadata":{"id":"7BobGQCxYSvB"}},{"cell_type":"markdown","source":["Fungsi `scraping_cnn(category=['Teknologi', 'Ekonomi', 'Olahraga'], num_data=150)` adalah sebuah fungsi Python yang digunakan untuk melakukan web scraping pada halaman web CNN Indonesia. Fungsi ini akan mengambil data dari beberapa kategori berita pada halaman web CNN Indonesia dan menyimpannya ke dalam sebuah file CSV. Fungsi ini akan mengambil 150 data untuk setiap kategori berita yang diberikan melalui parameter `category`.\n","\n","Dari hasil pencarian, tidak ditemukan informasi mengenai implementasi fungsi `scraping_cnn()` yang spesifik seperti yang tertera pada pertanyaan. Namun, berdasarkan penjelasan yang telah diberikan sebelumnya, dapat disimpulkan bahwa fungsi tersebut akan melakukan web scraping pada halaman web CNN Indonesia untuk mengambil data dari beberapa kategori berita yang diberikan. Fungsi ini akan mengambil data sebanyak `num_data` untuk setiap kategori berita yang diberikan melalui parameter `category`. Setelah semua data telah diambil, fungsi akan menyimpan data tersebut ke dalam sebuah file CSV dengan nama \"Data Berita CNN.csv\".\n"],"metadata":{"id":"J5GKIjQBpETE"}},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqYzBrlCv4kf","executionInfo":{"status":"ok","timestamp":1699616841255,"user_tz":-420,"elapsed":12478,"user":{"displayName":"Siti Ulun Nuha Karimah","userId":"02748323530668587194"}},"outputId":"2061e69e-889a-4312-fd6e-22262f4b73d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["['https://www.cnnindonesia.com/teknologi/20231110144858-192-1022576/pekerja-google-kritik-standar-ganda-perusahaan-soal-israel-palestina', 'Pekerja Google Kritik Standar Ganda Perusahaan Soal Israel-Palestina', 'Jumat, 10 Nov 2023 17:05 WIB', 'Sekelompok karyawanGoogle menerbitkan surat terbuka yang menyebut dugaan standar ganda di perusahaan tersebut terkait kebebasan berekspresi ihwal agresi Israel ke Palestina. Surat itu mengutuk \"kebencian, pelecehan dan pembalasan\" di dalam perusahaan terhadap para pekerja Muslim, Arab dan Palestina. Para karyawan yang menulis surat tersebut sengaja tidak mencantumkan nama mereka karena takut mendapat pembalasan. Mereka menuntut agar CEO Google Sundar Pichai, CEO Google Cloud Thomas Kurian, dan para pemimpin senior lainnya untuk secara terbuka mengutuk \"genosida yang sedang berlangsung dengan cara yang paling keras.\" Selain itu, mereka juga mendesak perusahaan untuk membatalkan Project Nimbus, sebuah kesepakatan senilai $1,2 miliar untuk memasok AI dan teknologi canggih lainnya kepada militer Israel. SCROLL TO CONTINUE WITH CONTENT \"Kami adalah karyawan Google yang beragama Islam, Palestina, dan Arab yang bergabung dengan rekan-rekan Yahudi yang anti-Zionis,\" demikian isisurat tersebut. \"Kami tidak bisa tinggal diam menghadapi kebencian, pelecehan, dan pembalasan yang kami alami di tempat kerja saat ini.\"  Surat tersebut mengutip contoh spesifik dari perilaku di tempat kerja yang penuh emosi dan tidak pantas. Termasuk di antaranya adalah para pegawai Google yang tidak disebutkan namanya yang menuduh warga Palestina mendukung terorisme, melakukan \"fitnah terhadap Nabi Muhammad,\" dan secara terbuka menyebut warga Palestina sebagai \"binatang\" di platform kerja resmi Google, mengutip Engadget. Kelompok ini menggambarkan direksi Google \"berpangku tangan\" dalam dua kasus terakhir, dan mengatakan bahwa para manajer Google telah menyebut karyawan \"gila\" dan \"tersesat\" karena mengekspresikan empati terhadap penduduk Gaza. Para karyawan mengatakan bahwa para manajer Google secara terbuka bertanya kepada orang-orang Arab dan Muslim di perusahaan tersebut apakah mereka mendukung Hamas sebagai tanggapan atas kepedulian mereka terhadap Palestina. \"Bahkan ada upaya terkoordinasi untuk menguntit kehidupan publik para karyawan yang bersimpati pada Palestina dan melaporkan mereka ke Google dan penegak hukum atas tuduhan \\'mendukung terorisme\\',\" demikian isi surat tersebut. Contoh lain yang dikutip termasuk \"seruan yang tulus\" untuk menyumbang ke badan amal bagi warga Gaza yang \"ditanggapi dengan berbagai komentar merendahkan martabat warga Gaza sebagai \\'binatang\\', mengabaikan penderitaan mereka, dan menyerukan kepada para karyawan Google untuk memboikot bantuan bagi warga sipil karena sekolah dan rumah sakit Palestina digunakan untuk \\'terorisme\\'.\" Surat tersebut juga menuduh para manajer Google menggunakan jabatan mereka untuk \"mempertanyakan, melaporkan, dan berusaha memecat para pekerja Google dari kalangan Muslim, Arab, dan Palestina yang menyatakan simpati terhadap penderitaan rakyat Palestina yang terkepung.\" Surat tersebut menggambarkan seorang manajer yang mendukung \"pengawasan terhadap karyawan Google di media sosial,\" dan kemudian secara terbuka melecehkan mereka di platform kerja Google.  ', 'Teknologi']\n","['https://www.cnnindonesia.com/ekonomi/20231110155934-92-1022626/harga-gula-naik-jadi-rp16-ribu-di-pengecer-papua-tembus-rp17-ribu', 'Harga Gula Naik Jadi Rp16 Ribu di Pengecer, Papua Tembus Rp17 Ribu', 'Jumat, 10 Nov 2023 18:13 WIB', 'Badan Pangan Nasional (Bapanas) menaikkan harga gula di toko ritel alias pengecermenjadi Rp16 ribu hingga Rp17 ribu per kg. Deputi Bidang Ketersediaan dan Stabilisasi Pangan Bapanas I Gusti Ketut Astawa mengatakan kenaikan dilakukan di tengah fenomena El Nino yang mengerek harga gula internasional. Ia berharap kebijakan ini bisa menjaga stabilitas pasokan dan harga di dalam negeri. \"Berdasarkan hasil input tersebut, kami mengimbau kepada seluruh pelaku usaha ritel untuk dapat mengimplementasikan relaksasi harga dimaksud,\" katanya dalam keterangan resmi, Kamis (9/11 SCROLL TO CONTINUE WITH CONTENT Kendati demikan, Bapanas mengatakan banderol Rp17 ribu per kg hanya berlaku di Maluku, Papua, serta wilayah Tertinggal, Terluar, Terpencil, dan Pedalaman (3TP).  Bapanas memprediksi produksi gula turun imbas El Nino dari estimasi awal 2,6 juta ton menjadi 2,3 juta ton. Di lain sisi, Ketut mengatakan realisasi impor gula kristal mentah (GKM) baru 180 ribu ton atau 22,61 persen dan gula kristal putih (GKP) 126.941 ton alias 58,82 persen. Ia mengungkap beberapa perusahaan yang punya kuota impor GKM belum merealisasikannya. Pada akhirnya, harga gula internasional yang tinggi membuat penjualan sesuai harga acuan pembelian (HAP) di tingkat konsumen sulit dilakukan. HAP gula diatur dalam Peraturan Badan Pangan Nasional (Perbadan) Nomor 17 Tahun 2023 yang menyebut HAP gula konsumsi di level produsen sebesar Rp12.500 per kg dan di tingkat konsumen Rp14.500 per kg. Sedangkan khusus wilayah Indonesia Timur dan daerah 3TP dipatok Rp15.500 per kg.  \"Jadi selain optimalisasi penyerapan dalam negeri dan percepatan importasi, diusulkan adanya fleksibilitas harga penjualan di tingkat konsumen. Ke depan, pelaku usaha ritel bisa menjual gula konsumsi dengan harga Rp16 ribu per kg,\" tandasnya. Sementara itu, Pusat Informasi Harga Pangan Strategis Nasional (PIHPS Nasional) mencatat harga gula pasir lokal di pasar modern masih Rp14.950 per kg. Sedangkan gula pasir kualitas premium dihargai Rp15.600 per kg. [Gambas:Video CNN] ', 'Ekonomi']\n","['https://www.cnnindonesia.com/olahraga/20231110182124-142-1022720/gibran-akui-laga-perdana-piala-dunia-u-17-2023-di-solo-sepi-penonton', 'Gibran Akui Laga Perdana Piala Dunia U-17 2023 di Solo Sepi Penonton', 'Jumat, 10 Nov 2023 18:35 WIB', 'Wali Kota SoloGibran Rakabuming Rakamengakui laga perdanaPiala Dunia U-17 2023 antara Mali vs Uzbekistan di Stadion Manahan, Solo, sepi penonton. Menurut data resmi, jumlah penonton tercatat sebanyak 3.014 orang. Tak sampai seperempat kapasitas Stadion Manahan yang mencapai 20 ribu penonton. Gibran mengakui minat warga untuk menonton pertandingan Piala Dunia U-17 di kotanya belum sebesar di Surabaya. SCROLL TO CONTINUE WITH CONTENT \"Ya [tadi sepi]. Tadi saya sudah koordinasi dengan FIFA yang ada di sini, ini memang keramaiannya terkonsentrasi di Surabaya,\" katanya di Stadion Manahan, Jumat (10/11). Pantauan CNNIndonesia.com, laga yang dimulai pukul 16.00 WIB itu didominasi kursi kosong. Penonton terkonsentrasi di tribune Timur dan Barat Stadion. Pemerintah Kota (Pemkot) Solo sebenarnya sudah berupaya agar pergelaran sepak bola junior tingkat internasional itu lebih dilirik warga. Tak sedikit baliho dan reklame yang dipasang Pemkot di lokasi-lokasi strategis di Solo dan sekitarnya. Tak hanya itu, Pemkot juga membagikan ratusan tiket gratis untuk suporter Persis Solo dan siswa-siswi SMP. \"[Penonton bertiket gratis] sudah masuk semua,\" kata Gibran. Putra Presiden Joko Widodo itu menyatakan pihaknya akan berupaya maksimal mempromosikan gelaran internasional di kotanya. Ia menargetkan pertandingan mendatang dapat disaksikan lebih banyak orang. \"Ini nanti akan kami genjot lagi di pertandingan berikutnya,\" katanya. Laga perdana Grup B antara Mali vs Uzbekistan berakhir dengan skor 3-0. Seluruh gol kemenangan Mali diborong Mamadou Doumbia. [Gambas:Video CNN] ', 'Olahraga']\n","Berhasil Mengambil data sebanyak 3 berita dengan 3 Category\n"]}],"source":["scraping_cnn(category=['Teknologi', 'Ekonomi', 'Olahraga'], num_data=1)"]},{"cell_type":"code","source":["df = pd.read_csv('Data Berita CNN.csv')\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"aUeEApYtJbQB","executionInfo":{"status":"ok","timestamp":1699616866046,"user_tz":-420,"elapsed":446,"user":{"displayName":"Siti Ulun Nuha Karimah","userId":"02748323530668587194"}},"outputId":"141b3a6c-bd4c-4581-e331-88b5ef23095f"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                 Url  \\\n","0  https://www.cnnindonesia.com/teknologi/2023111...   \n","1  https://www.cnnindonesia.com/ekonomi/202311101...   \n","2  https://www.cnnindonesia.com/olahraga/20231110...   \n","\n","                                               Judul  \\\n","0  Pekerja Google Kritik Standar Ganda Perusahaan...   \n","1  Harga Gula Naik Jadi Rp16 Ribu di Pengecer, Pa...   \n","2  Gibran Akui Laga Perdana Piala Dunia U-17 2023...   \n","\n","                        Tanggal  \\\n","0  Jumat, 10 Nov 2023 17:05 WIB   \n","1  Jumat, 10 Nov 2023 18:13 WIB   \n","2  Jumat, 10 Nov 2023 18:35 WIB   \n","\n","                                             Artikel   Category  \n","0  Sekelompok karyawanGoogle menerbitkan surat te...  Teknologi  \n","1  Badan Pangan Nasional (Bapanas) menaikkan harg...    Ekonomi  \n","2  Wali Kota SoloGibran Rakabuming Rakamengakui l...   Olahraga  "],"text/html":["\n","  <div id=\"df-c8d3ff06-a41d-4e76-b380-aa29e437d358\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Url</th>\n","      <th>Judul</th>\n","      <th>Tanggal</th>\n","      <th>Artikel</th>\n","      <th>Category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.cnnindonesia.com/teknologi/2023111...</td>\n","      <td>Pekerja Google Kritik Standar Ganda Perusahaan...</td>\n","      <td>Jumat, 10 Nov 2023 17:05 WIB</td>\n","      <td>Sekelompok karyawanGoogle menerbitkan surat te...</td>\n","      <td>Teknologi</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://www.cnnindonesia.com/ekonomi/202311101...</td>\n","      <td>Harga Gula Naik Jadi Rp16 Ribu di Pengecer, Pa...</td>\n","      <td>Jumat, 10 Nov 2023 18:13 WIB</td>\n","      <td>Badan Pangan Nasional (Bapanas) menaikkan harg...</td>\n","      <td>Ekonomi</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://www.cnnindonesia.com/olahraga/20231110...</td>\n","      <td>Gibran Akui Laga Perdana Piala Dunia U-17 2023...</td>\n","      <td>Jumat, 10 Nov 2023 18:35 WIB</td>\n","      <td>Wali Kota SoloGibran Rakabuming Rakamengakui l...</td>\n","      <td>Olahraga</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8d3ff06-a41d-4e76-b380-aa29e437d358')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c8d3ff06-a41d-4e76-b380-aa29e437d358 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c8d3ff06-a41d-4e76-b380-aa29e437d358');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-23bfe0d9-fe50-4d9d-b88f-4a409d43e3ec\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23bfe0d9-fe50-4d9d-b88f-4a409d43e3ec')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-23bfe0d9-fe50-4d9d-b88f-4a409d43e3ec button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Cek Jumlah Data"],"metadata":{"id":"PVNRpMBPz3Vr"}},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"zS5GZvQVz78S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699616841274,"user_tz":-420,"elapsed":47,"user":{"displayName":"Siti Ulun Nuha Karimah","userId":"02748323530668587194"}},"outputId":"1c13b1fb-7672-4b38-b7ea-cc929e554b9e"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(450, 5)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["## Cek Data Null"],"metadata":{"id":"oBH1GVBX0Aga"}},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"id":"4ss-2cPC0TNV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699616841274,"user_tz":-420,"elapsed":42,"user":{"displayName":"Siti Ulun Nuha Karimah","userId":"02748323530668587194"}},"outputId":"41656361-121d-4065-c0ad-73e0b9614ae4"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Url         0\n","Judul       0\n","Tanggal     0\n","Artikel     0\n","Category    0\n","dtype: int64"]},"metadata":{},"execution_count":18}]}]}